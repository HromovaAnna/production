{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load the environment variables from a .env file\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")  # Load the PRICE_DATA variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRICE_DATA загружена: C:/Data course setup/Microsoft VS Code/Project/price_data\n",
      "Найденные файлы: ['C:/Data course setup/Microsoft VS Code/Project/price_data\\\\price_data.parquet']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from glob import glob\n",
    "\n",
    "# Загружаем переменные окружения из файла .env\n",
    "load_dotenv()\n",
    "\n",
    "# Получаем значение переменной окружения PRICE_DATA\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "\n",
    "# Проверяем, было ли загружено значение\n",
    "if PRICE_DATA is None:\n",
    "    print(\"Ошибка: переменная окружения PRICE_DATA не загружена.\")\n",
    "else:\n",
    "    print(\"PRICE_DATA загружена:\", PRICE_DATA)\n",
    "\n",
    "# Теперь ищем все parquet файлы в директории PRICE_DATA\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"*.parquet\"))\n",
    "\n",
    "# Проверка найденных файлов\n",
    "print(\"Найденные файлы:\", parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
      "       'Stock Splits', 'ticker'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Загрузка данных из найденного parquet файла\n",
    "dd_px = dd.read_parquet(parquet_files[0])\n",
    "\n",
    "# Проверка названий столбцов\n",
    "print(dd_px.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление лагов для переменных Close\n",
    "dd_px['Close_lag'] = dd_px['Close'].shift(1)\n",
    "\n",
    "# Расчет доходности на основе Close\n",
    "dd_px['returns'] = (dd_px['Close'] / dd_px['Close_lag']) - 1\n",
    "\n",
    "# Добавление диапазона High-Low\n",
    "dd_px['hi_lo_range'] = dd_px['High'] - dd_px['Low']\n",
    "\n",
    "# Присвоение результата в новый Dask DataFrame\n",
    "dd_feat = dd_px[['Date', 'Close', 'Close_lag', 'returns', 'hi_lo_range', 'ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация Dask DataFrame в Pandas DataFrame\n",
    "df = dd_feat.compute()\n",
    "\n",
    "# Расчет 10-дневной скользящей средней доходности\n",
    "df['rolling_mean_returns'] = df['returns'].rolling(window=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date      Close  Close_lag   returns  hi_lo_range  \\\n",
      "0 2013-12-02 00:00:00-05:00  17.193993        NaN       NaN     0.421403   \n",
      "1 2013-12-03 00:00:00-05:00  17.664682  17.193993  0.027375     0.271371   \n",
      "2 2013-12-04 00:00:00-05:00  17.623508  17.664682 -0.002331     0.261078   \n",
      "3 2013-12-05 00:00:00-05:00  17.713970  17.623508  0.005133     0.272306   \n",
      "4 2013-12-06 00:00:00-05:00  17.468174  17.713970 -0.013876     0.223958   \n",
      "\n",
      "  ticker  rolling_mean_returns  \n",
      "0   AAPL                   NaN  \n",
      "1   AAPL                   NaN  \n",
      "2   AAPL                   NaN  \n",
      "3   AAPL                   NaN  \n",
      "4   AAPL                   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Вывод первых 5 строк DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRICE_DATA loaded: C:/Data course setup/Microsoft VS Code/Project/price_data\n",
      "Found files: ['C:/Data course setup/Microsoft VS Code/Project/price_data\\\\price_data.parquet']\n",
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
      "       'Stock Splits', 'ticker'],\n",
      "      dtype='object')\n",
      "                       Date      Close  Close_lag   returns  hi_lo_range  \\\n",
      "0 2013-12-02 00:00:00-05:00  17.193993        NaN       NaN     0.421403   \n",
      "1 2013-12-03 00:00:00-05:00  17.664682  17.193993  0.027375     0.271371   \n",
      "2 2013-12-04 00:00:00-05:00  17.623508  17.664682 -0.002331     0.261078   \n",
      "3 2013-12-05 00:00:00-05:00  17.713970  17.623508  0.005133     0.272306   \n",
      "4 2013-12-06 00:00:00-05:00  17.468174  17.713970 -0.013876     0.223958   \n",
      "\n",
      "  ticker  rolling_mean_returns  \n",
      "0   AAPL                   NaN  \n",
      "1   AAPL                   NaN  \n",
      "2   AAPL                   NaN  \n",
      "3   AAPL                   NaN  \n",
      "4   AAPL                   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load the environment variables from a .env file\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")  # Load the PRICE_DATA variable\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from glob import glob\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the value of the environment variable PRICE_DATA\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "\n",
    "# Check if the variable has been loaded successfully\n",
    "if PRICE_DATA is None:\n",
    "    print(\"Error: The environment variable PRICE_DATA has not been loaded.\")\n",
    "else:\n",
    "    print(\"PRICE_DATA loaded:\", PRICE_DATA)\n",
    "\n",
    "# Now find all parquet files in the PRICE_DATA directory\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"*.parquet\"))\n",
    "\n",
    "# Check the found files\n",
    "print(\"Found files:\", parquet_files)\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load data from the found parquet file\n",
    "dd_px = dd.read_parquet(parquet_files[0])\n",
    "\n",
    "# Check the column names\n",
    "print(dd_px.columns)\n",
    "\n",
    "# Add lags for the Close variable\n",
    "dd_px['Close_lag'] = dd_px['Close'].shift(1)\n",
    "\n",
    "# Calculate returns based on Close\n",
    "dd_px['returns'] = (dd_px['Close'] / dd_px['Close_lag']) - 1\n",
    "\n",
    "# Add the High-Low range\n",
    "dd_px['hi_lo_range'] = dd_px['High'] - dd_px['Low']\n",
    "\n",
    "# Assign the result to a new Dask DataFrame\n",
    "dd_feat = dd_px[['Date', 'Close', 'Close_lag', 'returns', 'hi_lo_range', 'ticker']]\n",
    "\n",
    "# Convert Dask DataFrame to Pandas DataFrame\n",
    "df = dd_feat.compute()\n",
    "\n",
    "# Calculate the 10-day rolling mean of returns\n",
    "df['rolling_mean_returns'] = df['returns'].rolling(window=10).mean()\n",
    "\n",
    "# Output the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It was necessary to convert to pandas to calculate the moving average return because Dask does not directly support the rolling window operations needed for this calculation. \n",
    "# While Dask is efficient for handling large datasets, certain functions, like rolling averages, are more straightforward to implement with pandas due to its extensive built-in functionality for such operations. \n",
    "# In this case, working with pandas allows for simpler and more intuitive syntax to achieve the desired result, even though it means losing some of the parallel processing benefits that Dask provides. \n",
    "# Ideally, it would be better to compute the rolling mean directly in Dask to take advantage of its distributed computing capabilities, but this requires more complex handling of rolling windows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
